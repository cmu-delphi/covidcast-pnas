\documentclass[9pt,twoside,lineno]{pnas-new}
% Use the lineno option to display guide line numbers if required.

\templatetype{pnassupportinginfo}

\input{../../common/prelim.tex}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


\title{Can Auxiliary Indicators Improve COVID-19 Forecasting and Hotspot  
  Prediction?} 

\author{Daniel J. McDonald, Jacob Bien, Alden Green, Addison J. Hu, Nat DeFries,
  Sangwon Hyun, Natalia L. Oliveira, James Sharpnack, Jingjing Tang, Robert
  Tibshirani, Valerie Ventura, Larry Wasserman, and Ryan J. Tibshirani} 
\correspondingauthor{Daniel J. McDonald.\\E-mail: daniel@stat.ubc.ca}

\begin{document}

\maketitle


\SItext



\input{supplement-text.tex}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/fcast-finalized-1} 

}

\caption{Forecasting performance using finalized data. Compare to Figure 3 in the manuscript.}\label{fig:fcast-finalized}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/hot-finalized-1} 

}

\caption{Hotspot prediction performance using finalized data. Compare to Figure 4 in the manuscript.}\label{fig:hot-finalized}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/fcast-honest-v-finalized-1} 

}

\caption{Forecast performance with vintage compared to finalized data. Using finalized data leads to overly optimistic performance.}\label{fig:fcast-honest-v-finalized}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/hot-honest-v-finalized-1} 

}

\caption{Hotspot prediction performance with vintage compared to finalized data. Using finalized data leads to overly optimistic performance.}\label{fig:hot-honest-v-finalized}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/wis-densities-1} 

}

\caption{WIS values from forecast models, which appear to be roughly log-Gaussian.}\label{fig:wis-densities}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/fcast-adjusted-1} 

}

\caption{Forecast performance (using vintage data), summarized by geometric mean.}\label{fig:fcast-adjusted}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/compare-states-to-hub} 

}

\caption{Forecast performance for AR and indicator models, each retrained at the state level, compared to models submitted to the COVID-19 Forecast Hub over the same period. The thin grey lines are individual models from the Hub; the light blue line is the Hub ensemble model. To align prediction dates as best as possible, we look at the AR and indicator model forecasts for 5, 12, 19, and 26 days ahead; this roughly corresponds to 1, 2, 3, and 4 weeks ahead, respectively, since in the Hub, models typically submit forecasts on a Tuesday for the epiweeks aligned to end on each of the following 4 Saturdays.}\label{fig:compare-to-hub}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/sign-test-1} 

}

\caption{P-values from a one-sided sign test for improved forecast performance of the indicator-assisted models. Each p-value corresponds to a forecast date. The alternative hypothesis is that the AR model is better (median difference between the relative WIS of the AR model and an indicator model is negative).}\label{fig:sign-test}
\end{figure}

\begin{table}

\caption{\label{tab:dm-test}P-values from a one-sided Diebold-Mariano test for improvemed forecast performance when adding the indicators. The alternative hypothesis is that the AR model is better.}
\centering
\begin{tabular}[t]{lrrrrr}
\toprule
metric & CHNG-CLI & CHNG-COVID & CTIS-CLIIC & DV-CLI & Google-AA\\
\midrule
Geometric mean & 0.072 & 0.036 & 0.005 & 0.032 & 0.026\\
Mean & 0.177 & 0.132 & 0.006 & 0.092 & 0.103\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/fcast-booted-1} 

}

\caption{Forecast performance when indicators are replaced with samples from their empirical distribution. Performance is largely similar to the AR model.}\label{fig:fcast-booted}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/fcast-booted-adjusted-1} 

}

\caption{Forecast performance as measured with the geometric mean when indicators are replaced with samples from their empirical distribution. Performance is largely similar to the AR model.}\label{fig:fcast-booted-adjusted}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/hot-booted-1} 

}

\caption{Hotspot prediction performance when indicators are replaced with samples from their empirical distribution. Performance is largely similar to the AR model.}\label{fig:hot-booted}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/upswing-summary-1} 

}

\caption{Average difference between the WIS of the AR model and of the indicator models, separated into up, down, and flat periods. The indicator models generally do best during down and flat periods.}\label{fig:upswing-summary}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/hotspots-upswing-downswing-1} 

}

\caption{Percentage change in classification error and log likelihood, relative that of the AR model, separated into up, down, and flat periods. Like the analogous forecasting analysis, the indicator models generally do better during down and flat periods.}\label{fig:hotspots-upswing-downswing}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/cor-wis-ratio-1} 

}

\caption{Histograms of the Spearman correlation between the ratio of forecaster WIS to AR WIS with the \% change in case rates, relative to case rates 7 days earlier.}\label{fig:cor-wis-ratio}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/upswing-corr-table-1} 

}

\caption{Correlation of the difference in WIS with the difference in median predictions (each difference being between the AR model and an indicator model), separated into up, down, and flat periods. In down periods, improvements in forecast error are highly correlated with lower median predictions. The opposite is true in up periods, but the conclusion here appears to be weaker.}\label{fig:upswing-corr-table}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/upswing-summary-remake-1} 

}

\caption{Percentage change in average WIS of the forecaster (AR or indicator assisted), relative to the baseline. All models perform poorly during down periods, but the indicators help. During flat periods, the indicators improve slightly over the AR. During up periods, all forecasters do much better than the baseline, but only some do as well as AR.}\label{fig:upswing-summary-remake}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/ccf-dv-finalized-1} 

}

\caption{Illustration of the cross-correlation function between DV-CLI and cases. The left panel shows the standardized signals over the period from August 1 to September 28 (as of May 15, 2021). The right panel shows $\CCF_{\ell}(a)$ for different values of $a$ as vertical blue bars. The orange dashed line indicates the 95\% significance threshold. By our leadingness/laggingness metric, DV-CLI is leading (but not lagging) cases over this period.}\label{fig:ccf-dv-finalized}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/lagging-only-1} 

}

\caption{Correlation of the difference in WIS with the laggingness of the indicator at the target date, stratified by up, down, or flat period. Compare to Figure 5 in the manuscript.}\label{fig:lagging-only}
\end{figure}

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/diff-in-lead-lag-1} 

}

\caption{Correlation of the difference between leadingness and laggingness with the difference in WIS. The relationship is essentially the same as described in the manuscript and shown in Figure 5.}\label{fig:diff-in-lead-lag}
\end{figure}

\clearpage

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/cumulative-mean-1} 

}

\caption{Cumulative sum of WIS for each forecaster divided by the cumulative sum of WIS for the baseline model. The shaded background shows national case incidence for the 14-day ahead target. Hash marks along the x-axis denote weeks.}\label{fig:cumulative-mean}
\end{figure}

\clearpage

\clearpage

\begin{figure}

{\centering \includegraphics[width=\textwidth]{fig/errs-in-space-1} 

}

\caption{Percentage improvement in WIS, relative to the AR forecaster, by HRR (negative numbers indicate improved performance, positives indicate worsening).}\label{fig:errs-in-space}
\end{figure}


\FloatBarrier



\dataset{predictions.zip}{Archived {\tt .RDS} (R objects) files containing
  all predictions for forecasting and hotspots using vintage and finalized data.
Persistent DOI to be added at publication.}

\dataset{evaluations.zip}{Archived {\tt .RDS} (R objects) files containing
  all evaluations for forecasting and hotspots using vintage and finalized data.
  Persistent DOI to be added at publication.}

\dataset{analysis.zip}{Archived {\tt .RDS} (R objects) files containing
  additional data used to produce graphics and conclusions in the manuscript.
  Persistent DOI to be added at publication.}

\dataset{code.zip}{R script files containing
  all code used to reproduce the analysis described in the manuscript.
  Persistent DOI to be added at publication.}



\bibliography{../../common/covidcast.bib}

\end{document}