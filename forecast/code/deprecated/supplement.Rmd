
\clearpage

<!-- Comparison to submitted forecasts -->

```{r grab-submitted-case-fcasts}
library(aws.s3)
Sys.setenv("AWS_DEFAULT_REGION" = "us-east-2")
s3bucket <- get_bucket("forecast-eval")
# ensure that forecasters have submitted a reasonable amount
n_keeper_weeks <- 6L
n_keeper_locs <- 50L
case_scores <- s3readRDS("score_cards_state_cases.rds", s3bucket) %>% 
  mutate(forecast_date = target_end_date - ahead * 7) %>% 
  # fix weirdnesses about submission dates, 
  # this is generous to the forecaster
  filter(forecast_date < "2021-01-01", ahead < 4) %>% 
  select(ahead, geo_value, forecaster, target_end_date, wis, forecast_date)

strawman <- case_scores %>% filter(forecaster == "COVIDhub-baseline")
case_scores <- left_join(
  case_scores, 
  strawman %>% 
    select(forecast_date, target_end_date, geo_value, wis) %>% 
    rename(strawman_wis = wis)
) %>% filter(forecaster != "COVIDhub-baseline")

# Subset to those forecasters that submitted enough 14-day ahead forecasts
n_submitted <- case_scores %>% 
  filter(ahead == 2) %>% 
  group_by(forecaster) %>% 
  summarise(nfcasts = n())
keepers <- n_submitted %>% 
  filter(nfcasts / n_keeper_locs > n_keeper_weeks - .0001, 
         forecaster != "COVIDhub-4_week_ensemble") %>% # same as CH-Ensemble 
  pull(forecaster)

case_scores <- case_scores %>% 
  filter(forecaster %in% keepers) %>%
  group_by(forecaster, ahead) %>%
  summarise(rel_wis = Mean(wis) / Mean(strawman_wis),
            geo_wis1 = GeoMean((wis + 1) / (strawman_wis + 1)),
            geo_wis = GeoMean(wis / strawman_wis))
```

```{r compare-to-hub-mean, fig.height = 8.5, fig.cap="This figure reproduces Figure 3 in the main paper but overlays scores for the forecasts submitted to the COVID-19 Forecast Hub. Grey lines correspond to the various teams that submitted during period our evaluation period. We have highlighted the COVIDhub-ensemble, which is the official forecast of the CDC.", include=FALSE}
# Same as Fig 3 in the paper
df <- summarizer(fcasts_honest %>%
                   group_by(ahead, forecaster), "wis", NULL, 
                 "strawman_wis", Mean, c("aggr","scale"))
ggplot(df) +
  geom_line(aes(ahead, wis, color = forecaster)) + 
  geom_point(aes(ahead, wis, color = forecaster)) +
  theme_bw() +
  geom_hline(yintercept = 1, size = 1.5) +
  xlab("Days ahead") +
  ylab("Mean WIS (relative to baseline)") +
  scale_color_manual(values = c(fcast_colors, "CH-ensemble" = "lightblue"),
                     guide = guide_legend(nrow = 2)) +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  geom_line(data = case_scores, 
            aes(ahead * 7, rel_wis, group = forecaster),
            color = "grey70") +
  geom_line(data = case_scores %>% filter(forecaster == "COVIDhub-ensemble"),
            aes(ahead * 7, rel_wis), color = "lightblue", size = 1.5) +
  scale_y_log10()
```

\clearpage

```{r compare-to-hub-geomean, fig.height = 8.5, fig.cap="This figure is similar to Figure \\ref{fig:fcast-adjusted}. In this case, we add 1 to both the forecaster WIS and the baseline WIS before scaling (to allow forecasters that achieve 0 error to appear), and we overlay scores for the forecasts submitted to the COVID-19 Forecast Hub. Grey lines correspond to the various teams that submitted during period our evaluation period. We have highlighted the COVIDhub-ensemble, which is the official forecast of the CDC.", include=FALSE}
# Like supplement GeoMean figure, but adding 1
df2 <- fcasts_honest %>% 
  group_by(ahead, forecaster) %>%
  summarise(wis = GeoMean((wis + 1) / (strawman_wis + 1)))

ggplot(df2) +
  geom_line(aes(ahead, wis, color = forecaster)) + 
  geom_point(aes(ahead, wis, color = forecaster)) +
  theme_bw() +
  geom_hline(yintercept = 1, size = 1.5) +
  xlab("Days ahead") +
  ylab("Geometric mean WIS (relative to baseline)") +
  scale_color_manual(values = c(fcast_colors, "CH-ensemble" = "lightblue"),
                     guide = guide_legend(nrow = 2)) +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  geom_line(data = case_scores, 
            aes(ahead * 7, geo_wis1, group = forecaster),
            color = "grey70") +
  geom_line(data = case_scores %>% filter(forecaster == "COVIDhub-ensemble"),
            aes(ahead * 7, geo_wis1), color = "lightblue", size = 1.5) +
  scale_y_log10()
```

```{r hotspots-upswing-downswing-remake, fig.cap="REMAKE: Classification and loglikelihood separated into periods of upswing, downswing, and flat cases. The indicator assisted models always have lower classification error relative to the null classifier, while the AR actually does worse in down and flat periods. In terms of loglikelihood, all forecasters have lower likelihood than the null classifier during up periods. In down and flat periods, the indicators generally improve over the AR, while the are worse during up periods.", eval=FALSE}
# mycummean <- function(x) {
#   isgood <- ! is.na(x)
#   denom <- cumsum(isgood)
#   x[!isgood] <- 0
#   num <- cumsum(x)
#   y <- num / denom
#   y[is.na(y)] <- .5 # deal with empties at the beginning
#   y
# }
# 
# null_classifier <- readRDS(here("data", 
#                                 "all_signals_wide_as_of_2020-05-18.RDS")) %>%
#   rename(jhu = `value+0:jhu-csse_confirmed_7dav_incidence_prop`) %>%
#   select(geo_value, time_value, jhu) %>%
#   group_by(geo_value) %>%
#   arrange(time_value) %>%
#   mutate(lag_value = lag(jhu, 7),
#          apc = (jhu - lag_value) / lag_value,
#          hot = case_when(
#            apc > .25 & lag_value > 30 ~ 1,
#            apc <= .25 & lag_value > 30 ~ 0),
#          null_class = mycummean(hot))
  
hot_udf <- inner_join(
  hotspots_honest,
  up_down %>% select(geo_value, target_end_date, udf))

cutoff <- mean(hot_udf %>% filter(forecaster == "AR") %>% pull(actual))

con_tab <- hot_udf %>% 
  filter(!is.na(actual)) %>%
  mutate(pred = value > .5) %>%
  group_by(forecaster, udf) %>%
  summarise(m = (mean(pred != actual) - cutoff) / cutoff,
            err = mean(pred != actual)) %>%
  ungroup()

# con_tab <- left_join(
#   con_tab %>% filter(forecaster != "AR"),
#   con_tab %>% filter(forecaster == "AR") %>%
#     select(-forecaster) %>%
#     rename(mar = m))

llike_tab <- hot_udf %>%
  filter(!is.na(actual)) %>%
  # left_join(null_classifier %>% select(geo_value, time_value, null_class) %>%
  #             rename(target_end_date = time_value)) %>%
  mutate( # kill prob 0-1 predictions
    value = case_when(
      value < 1e-8 ~ 1e-8,
      value > 1-1e-8 ~ 1-1e-8,
      TRUE ~ value),
    # null_class = case_when(
    #   null_class < 1e-8 ~ 1e-8,
    #   null_class > 1-1e-8 ~ 1-1e-8,
    #   TRUE ~ null_class),
    llike = (actual == 1) * log(value) + (actual == 0) * log(1 - value),
    nulldev = (actual == 1) * log(cutoff) + 
      (actual == 0) * log(1 - cutoff)) %>%
  group_by(forecaster, udf) %>%
  summarise(m = (mean(llike) - mean(nulldev)) / abs(mean(nulldev)),
            mm = mean(llike),
            mmm = mean(nulldev)) %>%
  ungroup()

# llike_tab <- left_join(
#   llike_tab %>% filter(forecaster != "AR"),
#   llike_tab %>% filter(forecaster == "AR") %>%
#     select(-forecaster) %>%
#     rename(mar = m))

bind_rows(con_tab %>% mutate(err = "Classification error"), 
          llike_tab %>% mutate(err = "Log likelihood")) %>%
  ggplot(aes(udf, m , fill = forecaster)) +
  geom_bar(width = 0.6, position = position_dodge(width=0.6),
           stat = "identity") +
  scale_fill_manual(values = fcast_colors, guide = guide_legend(nrow = 1)) +
  #scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  geom_hline(yintercept = 0) +
  scale_y_continuous(labels = scales::percent_format()) +
  facet_wrap(~err, scales = "free_y") +
  ylab("Improvement relative to the null classifier") +
  xlab("") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

```{r cor-wis-ratio-m1, eval = FALSE, fig.cap="This is Alden's second set of histograms. Here we have the correlation of the absolute value of WIS ratio - 1 with the percent change in 7dav cases relative to 7 days earlier"}
ggplot(pct_chng_df %>% 
         group_by(forecaster) %>% 
         mutate(median = median(cor_abs_wisratio_minus_1_pctchange)), 
       aes(x = cor_abs_wisratio_minus_1_pctchange)) +
  geom_histogram(aes(y = ..count.. / sum(..count..), fill = forecaster), bins = 50) +
  scale_fill_manual(values = fcast_colors) +
  theme_bw() +
  theme(legend.position = "none") +
  geom_vline(aes(xintercept = median), linetype = "dotted") + 
  geom_vline(xintercept = 0) +
  facet_wrap(~forecaster) + 
  xlab("Spearman correlation") + ylab("Relative frequency") +
  scale_y_continuous(labels = scales::label_percent(accuracy = 1))
```

```{r upswing-histogram-logged, eval = FALSE, fig.cap="Not sure if we want this here. Similar to Figure 5 in the manuscript but taking logs. "}
up_down_df %>% 
  group_by(forecaster, udf) %>%
  ggplot(aes((AR_wis + 1) / (wis + 1), fill = forecaster)) +
  geom_histogram(bins = 100) +
  facet_grid(udf ~ forecaster) +
  theme_bw() +
  ylab("Count") +
  theme(legend.position = "none") +
  scale_fill_manual(values = fcast_colors) +
  scale_x_log10() +
  scale_y_log10(breaks = c(10,1000,100000), 
                labels = trans_format("log10", math_format(10^.x))) +
  xlab("AR WIS - forecaster WIS") +
  geom_vline(xintercept = 1)
```

```{r leading-and-lagging, eval=FALSE}
# Deprecated
df2 %>%
  group_by(forecaster, udf) %>%
  summarise(
    leadingness = cor(AR_wis - wis, leading, use = "pairwise.complete.obs"),
    laggingness = cor(AR_wis - wis, lagging, use = "pairwise.complete.obs")) %>%
  pivot_longer(leadingness:laggingness) %>%
  ggplot(aes(udf, value, fill = forecaster)) +
  geom_bar(width = 0.6, position = position_dodge(width=0.6),
           stat = "identity") +
  geom_hline(yintercept = 0) +
  scale_fill_manual(values = fcast_colors) +
  facet_wrap(~name) +
  theme_bw() +
  ylab("Correlation") +
  xlab("") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


```{r fcast-gs-locations, eval=FALSE}
plotter(fcasts_gs %>% filter(period != "jm"),
        "wis", Mean, scaler = "strawman_wis", 
        order_of_operations = c("aggr","scale")) +
  ylab("Mean WIS (relative to baseline)")
```

```{r fcast-gs-locations-adjusted, eval=FALSE}
plotter(fcasts_gs %>% filter(period != "jm"), 
        "wis", GeoMean, scaler = "strawman_wis", 
        order_of_operations = c("scale","aggr")) +
  ylab("Geometric mean WIS (relative to baseline)")
```

```{r hot-gs-locations, eval=FALSE}
plotter_hotspots(hotspots_gs %>% filter(period != "jm")) +
  geom_hline(yintercept = 0.5)
```

```{r traj-data, eval = FALSE}
source(here("code", "deprecated", "trajectory_plot_funs.R"))
preds <- readRDS(here("data", "predictions_honest.RDS"))
traj_best <- get_trajectory_plots(fcasts_honest, preds, actuals, hrr_tab, 
                                  "only2020", "best")
traj_worst <- get_trajectory_plots(fcasts_honest, preds, actuals, hrr_tab,
                                   "only2020", "worst")
rm(preds)
```

```{r trajectory-plots, eval = FALSE}
for (nm in names(traj_best)) print(trajectory_panel(nm, traj_best, traj_worst))
```